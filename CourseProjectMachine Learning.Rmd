---
title: "Practical Machine Learning Course Project"
author: "D Arnelle"
date: "June 14, 2016"
output: html_document
---

```{r setup, include="FALSE"}
knitr::opts_chunk$set(echo = "TRUE")
```
##Introduction
The goal of the project is to create a machine learning algorithm using the data from accelerometers on the belt, forearm, arm and barbell to predict how well a barbell lifting exercise was performed by the study participants. The "classe" variable in the data set is a human assessment of exercise execution form to be used as the outcome. Since a five level factor variable is used as the outcome, classification by trees was used as a primary approach. 
###Data exploration
First, a random seed was set to 3539 and the data from the csv file was read using the read.csv defaults. The data set was large, and graphical examination of the data with the featurePlot function was unlikely to be helpful at this stage. Instead, both the str and summary functions were run to examine the data (output not shown).
```{r set_up}
set.seed(3539) # set seed for reproducibility
library(lattice)
library(ggplot2)
library(caret)
library(e1071)
library(plyr)
library(rpart)
library(gbm)
library(survival)
library(splines)
library(parallel)
```

```{r initial_read, eval = FALSE}
training <-read.csv("pml-training.csv", header = TRUE) 
summary(training)
str(training)
```
A large number of NAs (19216 out of 19622 in many cases) and blank/Other/DIV#/0 values in the dataset were found. Since so much data was lacking, imputting data to cover the gaps was not likely to be useful and these variables are probably not important for the algorithm. A great number of factor variables with a few "number" levels are present as well; these are likely to be variables with a lot of missing data. The variables containing "timestamp" are also unlikely to be useful as absolute values. Neither the user_name nor X variables will be needed for prediction since these variables do not address how the exercise was carried out. The variables mentioned above and any near zero variance variables will be eliminated before starting the analysis. 

The dataset was imported again with stringsAsFactors set to FALSE and na.strings set to include blank, #DIV/0! and NA values. These changes to the read.csv function made elimination of the columns with a lot of missing data simpler during data cleaning below. The training set was then split into a new training set and  a validation set. The validation set was used to assess out of sample error after models were built.
```{r get_training}
training <-read.csv("pml-training.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = c("","#DIV/0!","NA"))
inTrain <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
training <- training[inTrain,]
validation <- training[-inTrain,] # save a data set for out of sample estimation
```
##Data Cleaning
Columns with near zero variance values, a large number of NA values or other problems noted above will need to be discarded. Since these operations will need to be applied to both the training and validation sets, a cleaner function was created. First, the nzv function was used to find columns with near zero variance values in the training set. Second, the cleaner function identified columns with many missing values using the table generated by the summary function and removed X, user_name, nzv, timestamp and variables with a large number of NA values from training and validation sets. Out of the initial 160 variables, 54 variables remained for model building. 

```{r cleaning}
cleaner <- function (zeroVarCol, df) {
    df0 <- df[,-zeroVarCol] # remove near zero variance columns
    sub <- colnames(df0) # get column names
    lose <- grepl("timestamp", sub) # find timestamp columns
    df1 <- df0[,!lose] # remove timestamp columns
 #   sub <- colnames(df1)
 #   lose <- grepl("window", sub) # find window columns
 #   df2 <- df1[,!lose] # remove window columns    
    df2 <- subset(df1, select= c(-X, -user_name)) # remove X and user_name columns
    df3 <- df2[ , sapply(df2, function(x){ !any(is.na(x)) } )]
}
z = nzv(training) # get columns with near zero variance for removal
train3 = cleaner(z,training) # remove columns by subsetting
valid3 = cleaner(z,validation) # remove columns by subsetting
```
###Model building
Random forests and boosting are very effective methods in machine learning. The random forest model was tried but was too computationally intensive, taking over 20 hours to build. A less computationally intensive boosting methods was used: Quinlan's C5.0 model. The model was cross-validated through 10 fold resampling of the training set repeated three times, with the caret package, using the training data frame with 54 variables.
```{r models}
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5)
#modelgbm <- train(classe ~., data = train3, method = "gbm", trControl = cvCtrl, verbose = FALSE)
modelC50 <- train(classe ~., data = train3, method = "C5.0", trControl = cvCtrl,  verbose = FALSE)
#modelgbm
modelC50
```
###Accuracy and out of sample error
The model was built using the train function of the caret package, with the method set to "C5.0". The "classe" variable was automatically converted to a factor variable by the caret package. Once the model was built, the validation set was used to test the model for accuracy and for an assessment of out of sample error.
```{r prediction}
#gbmPre=predict(modelgbm,newdata=validation)
c50Pre=predict(modelC50,newdata=validation)
```
Quinlan's C5.0 model gave 100% accuracy on the validation set. The model probably over-estimates the real-world accuracy; however, the out of sample error is likely to be small in any case.
```{r accuracy}
#  accuracy on validation set
#confusionMatrix(gbmPre,validation$classe)
confusionMatrix(c50Pre,validation$classe)
```

